# main.py ‚Äî —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –±–æ—Ç–∞
import asyncio, os, pathlib
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, F
from aiogram.types import Message, CallbackQuery, FSInputFile
from aiogram.filters import CommandStart
from aiogram.fsm.context import FSMContext

from tg_bot.db import engine
from tg_bot.models import Base
from tg_bot.utils.credits import ensure_user, get_credits, spend_credits
from tg_bot.keyboards import main_menu, voices_menu, frame_choice_menu, voice_choice_menu
from tg_bot.states import HookGen, AudioGen, FrameEdit, VideoGen
from tg_bot.services.openai_service import generate_hooks
from tg_bot.services.elevenlabs_service import tts_to_file, DEFAULT_VOICES
from tg_bot.services.higgsfield_service import edit_image, create_talking_video
from tg_bot.services.vertex_service import generate_video_veo3
from tg_bot.utils.files import list_start_frames
from tg_bot.utils.user_state import (
    get_selected_frame,
    set_selected_frame,
    get_selected_voice,
    set_selected_voice,
    get_last_audio,
    set_last_audio,
)
from tg_bot.utils.voices import list_voice_samples

load_dotenv()
print("DEBUG TELEGRAM_BOT_TOKEN:", os.environ.get("TELEGRAM_BOT_TOKEN"))
base_dir_env = os.getenv("BASE_DIR")
if base_dir_env is None:
    print("Warning: BASE_DIR is not set in the environment. Using current directory as BASE_DIR.")
    BASE_DIR = pathlib.Path(".")
else:
    BASE_DIR = pathlib.Path(base_dir_env)

bot = Bot(token=os.environ["TELEGRAM_BOT_TOKEN"])
dp = Dispatcher()

# –í—ã–±–æ—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∞—É–¥–∏–æ —Ç–µ–ø–µ—Ä—å —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ë–î

@dp.startup()
async def on_startup():
    # —Å–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—ã
    Base.metadata.create_all(bind=engine)

@dp.message(CommandStart())
async def cmd_start(m: Message):
    ensure_user(m.from_user.id)
    await m.answer(
        "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ GenAI UGC Ads –±–æ—Ç.\n–£ —Ç–µ–±—è 10 —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö –∫—Ä–µ–¥–∏—Ç–æ–≤. –ß—Ç–æ –¥–µ–ª–∞–µ–º?",
        reply_markup=main_menu()
    )

@dp.callback_query(F.data == "credits")
async def show_credits(c: CallbackQuery):
    cts = get_credits(c.from_user.id)
    await c.message.answer(f"–£ —Ç–µ–±—è —Å–µ–π—á–∞—Å {cts} –∫—Ä–µ–¥–∏—Ç–æ–≤.", reply_markup=main_menu())
    await c.answer()

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö—É–∫–æ–≤ ---
@dp.callback_query(F.data == "hooks")
async def ask_desc(c: CallbackQuery, state: FSMContext):
    await state.set_state(HookGen.waiting_description)
    await c.message.answer("–û–ø–∏—à–∏ –ø—Ä–æ–¥—É–∫—Ç –∏ –∞–∫—Ü–∏—é –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π. –ü—Ä–∏–º–µ—Ä: ¬´–ù–æ–≤—ã–µ –ø—Ä–æ—Ç–µ–∏–Ω–æ–≤—ã–µ –±–∞—Ç–æ–Ω—á–∏–∫–∏, -20% –¥–æ –ø—è—Ç–Ω–∏—Ü—ã¬ª.")
    await c.answer()

@dp.message(HookGen.waiting_description)
async def do_hooks(m: Message, state: FSMContext):
    await m.answer("–î—É–º–∞—é –Ω–∞–¥ 3‚Äì4 —Ö—É–∫-—Ñ—Ä–∞–∑–∞–º–∏‚Ä¶")
    hooks = await generate_hooks(m.text, n=4)
    txt = "–ì–æ—Ç–æ–≤–æ:\n" + "\n".join([f"{i+1}) {h}" for i,h in enumerate(hooks)])
    await m.answer(txt, reply_markup=main_menu())
    await state.clear()

# --- –í—ã–±–æ—Ä —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ –∫–∞–¥—Ä–∞ ---
@dp.callback_query(F.data == "pick_frame")
async def pick_frame(c: CallbackQuery):
    frames = list_start_frames()[:5]
    if not frames:
        await c.message.answer("–ü–æ–∫–∞ –Ω–µ—Ç —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤. –°–≤—è–∂–∏—Ç–µ—Å—å —Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º.")
        return await c.answer()
    for idx, frame in enumerate(frames):
        await c.message.answer_photo(
            FSInputFile(frame),
            caption=f"–ö–∞–¥—Ä #{idx+1}"
        )
    await c.message.answer(
        "–í—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ –∫–∞–¥—Ä–∞:",
        reply_markup=frame_choice_menu(len(frames))
    )
    await c.answer()

# --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ –∫–∞–¥—Ä–∞ ---
@dp.callback_query(F.data.startswith("frame_pick:"))
async def pick_frame_choice(c: CallbackQuery):
    idx = int(c.data.split(":",1)[1])
    frames = list_start_frames()[:5]
    if idx < 0 or idx >= len(frames):
        await c.message.answer("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä –∫–∞–¥—Ä–∞.")
        return await c.answer()
    set_selected_frame(c.from_user.id, frames[idx])
    print(f"User {c.from_user.id} –≤—ã–±—Ä–∞–ª –∫–∞–¥—Ä {frames[idx]}")
    await c.message.answer(f"–í—ã–±—Ä–∞–Ω —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∫–∞–¥—Ä #{idx+1}.", reply_markup=main_menu())
    await c.answer()

# --- –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–¥—Ä–∞ ---
@dp.callback_query(F.data == "edit_frame")
async def ask_edit(c: CallbackQuery, state: FSMContext):
    if not get_selected_frame(c.from_user.id):
        await c.message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∫–∞–¥—Ä.")
        return await c.answer()
    await state.set_state(FrameEdit.waiting_prompt)
    await c.message.answer("–ù–∞–ø–∏—à–∏ –ø—Ä–æ–º—Ç –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–¥—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–¥–æ–±–∞–≤—å –ª–æ–≥–æ—Ç–∏–ø –≤ —É–≥–ª—É, —Ñ–æ–Ω ‚Äî —Å—É–ø–µ—Ä–º–∞—Ä–∫–µ—Ç¬ª).")
    await c.answer()

@dp.message(FrameEdit.waiting_prompt)
async def do_edit(m: Message, state: FSMContext):
    try:
        src = get_selected_frame(m.from_user.id)
        await m.answer("–†–µ–¥–∞–∫—Ç–∏—Ä—É—é –∫–∞–¥—Ä‚Ä¶")
        edited_path = await edit_image(src, m.text)
        set_selected_frame(m.from_user.id, edited_path)
        await m.answer_photo(FSInputFile(edited_path), caption="–ù–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –∫–∞–¥—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
    except Exception as e:
        await m.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å: {e}")
    finally:
        await state.clear()

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ (TTS) ---
@dp.callback_query(F.data == "gen_audio")
async def ask_audio_text(c: CallbackQuery, state: FSMContext):
    samples = list_voice_samples()[:5]
    if not samples:
        await c.message.answer("–ü–æ–∫–∞ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤. –°–≤—è–∂–∏—Ç–µ—Å—å —Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º.")
        return await c.answer()
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ –æ–¥–Ω–æ–º—É –∞—É–¥–∏–æ —Å –ø–æ–¥–ø–∏—Å—å—é
    for idx, (name, voice_id, path) in enumerate(samples):
        await c.message.answer_audio(
            FSInputFile(path),
            caption=f"–ì–æ–ª–æ—Å #{idx+1}: {name}"
        )
    await c.message.answer(
        "–í—ã–±–µ—Ä–∏ –Ω–æ–º–µ—Ä –≥–æ–ª–æ—Å–∞:",
        reply_markup=voice_choice_menu(len(samples))
    )
    await c.answer()

@dp.callback_query(F.data.startswith("voice_pick:"))
async def set_voice(c: CallbackQuery, state: FSMContext):
    idx = int(c.data.split(":",1)[1])
    samples = list_voice_samples()[:5]
    if idx < 0 or idx >= len(samples):
        await c.message.answer("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä –≥–æ–ª–æ—Å–∞.")
        return await c.answer()
    name, voice_id, _ = samples[idx]
    set_selected_voice(c.from_user.id, voice_id)
    await c.message.answer(f"–ì–æ–ª–æ—Å –≤—ã–±—Ä–∞–Ω: {name}. –¢–µ–ø–µ—Ä—å –ø—Ä–∏—à–ª–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–¥–æ 1000 —Å–∏–º–≤–æ–ª–æ–≤).")
    await state.set_state(AudioGen.waiting_text)
    await c.answer()

@dp.message(AudioGen.waiting_text)
async def do_audio(m: Message, state: FSMContext):
    try:
        voice_id = get_selected_voice(m.from_user.id)
        await m.answer("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∞—É–¥–∏–æ‚Ä¶")
        path = await tts_to_file(m.text, voice_id)
        set_last_audio(m.from_user.id, path)
        await m.answer_audio(FSInputFile(path), caption="–ì–æ—Ç–æ–≤–æ. –ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
        
        # Clean up audio file after sending
        import os
        try:
            os.remove(path)
            print(f"Cleaned up audio file: {path}")
        except Exception as cleanup_error:
            print(f"Failed to cleanup audio file {path}: {cleanup_error}")
    except Exception as e:
        print(f"TTS Error for user {m.from_user.id}: {e}")  # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –¥–µ–±–∞–≥–∞
        await m.answer("–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ. –ú—ã —É–∂–µ —á–∏–Ω–∏–º –ø—Ä–æ–±–ª–µ–º—É, –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
    finally:
        await state.clear()

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é Veo3 (-1 –∫—Ä–µ–¥–∏—Ç) ---
@dp.callback_query(F.data == "video_duration")
async def ask_video_duration(c: CallbackQuery):
    from tg_bot.keyboards import video_duration_menu
    await c.message.edit_text(
        "üé¨ –í—ã–±–µ—Ä–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ:",
        reply_markup=video_duration_menu()
    )
    await c.answer()

@dp.callback_query(F.data.startswith("video_dur_"))
async def ask_video_prompt(c: CallbackQuery, state: FSMContext):
    duration = int(c.data.split("_")[-1])  # –ò–∑–≤–ª–µ–∫–∞–µ–º 4, 6 –∏–ª–∏ 8
    await state.update_data(video_duration=duration)
    
    duration_text = {
        4: "4 —Å–µ–∫—É–Ω–¥—ã (–±—ã—Å—Ç—Ä–æ)",
        6: "6 —Å–µ–∫—É–Ω–¥ (—Å—Ä–µ–¥–Ω–µ)", 
        8: "8 —Å–µ–∫—É–Ω–¥ (–¥–ª–∏–Ω–Ω–æ)"
    }
    
    await state.set_state(VideoGen.waiting_prompt)
    await c.message.edit_text(
        f"üé¨ –û—Ç–ª–∏—á–Ω–æ! –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration_text[duration]}\n\n"
        "–¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–∏ –ø—Ä–æ–º—Ç –¥–ª—è –≤–∏–¥–µ–æ.\n\n"
        "–ù–∞–ø—Ä–∏–º–µ—Ä: '–î–µ–≤—É—à–∫–∞ —Ç–∞–Ω—Ü—É–µ—Ç –Ω–∞ –ø–ª—è–∂–µ, –∑–∞–∫–∞—Ç, –∫—Ä–∞—Å–∏–≤—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è'\n\n"
        "–í–∏–¥–µ–æ –±—É–¥–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ 9:16 (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ)."
    )
    await c.answer()

@dp.callback_query(F.data == "back_to_main")
async def back_to_main(c: CallbackQuery, state: FSMContext):
    from tg_bot.keyboards import main_menu
    await c.message.edit_text(
        "ü§ñ –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:",
        reply_markup=main_menu()
    )
    await state.clear()
    await c.answer()

@dp.message(VideoGen.waiting_prompt)
async def do_video(m: Message, state: FSMContext):
    # –°–ø–∏—Å—ã–≤–∞–µ–º –∫—Ä–µ–¥–∏—Ç –∑–∞—Ä–∞–Ω–µ–µ (fail-fast)
    ok = spend_credits(m.from_user.id, 1, "veo3_video")
    if not ok:
        await m.answer("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ (–Ω—É–∂–µ–Ω 1). –ü–æ–ø–æ–ª–Ω–∏ —É –∞–¥–º–∏–Ω–∞.")
        return await state.clear()

    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        data = await state.get_data()
        duration = data.get("video_duration", 6)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 6 —Å–µ–∫—É–Ω–¥
        
        await m.answer(f"–ì–µ–Ω–µ—Ä–∏—Ä—É—é –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é Veo3 ({duration} —Å–µ–∫)‚Ä¶ —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 2-3 –º–∏–Ω—É—Ç—ã.")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Vertex AI Veo3
        video_path = await generate_video_veo3(
            prompt=m.text.strip(),
            duration_seconds=duration,
            aspect_ratio="9:16"
        )
        
        if video_path:
            await m.answer_video(FSInputFile(video_path), caption="–ì–æ—Ç–æ–≤–æ! (-1 –∫—Ä–µ–¥–∏—Ç —Å–ø–∏—Å–∞–Ω)")
            
            # Clean up video file after sending
            import os
            try:
                os.remove(video_path)
                print(f"Cleaned up video file: {video_path}")
            except Exception as cleanup_error:
                print(f"Failed to cleanup video file {video_path}: {cleanup_error}")
        else:
            raise Exception("Video generation failed")
            
    except Exception as e:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—Ä–µ–¥–∏—Ç –ø—Ä–∏ —Ñ–µ–π–ª–µ
        from tg_bot.utils.credits import add_credits
        add_credits(m.from_user.id, 1, "refund_video_fail")
        print(f"Veo3 Error for user {m.from_user.id}: {e}")  # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –¥–µ–±–∞–≥–∞
        await m.answer("–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ. –ú—ã —É–∂–µ —á–∏–Ω–∏–º –ø—Ä–æ–±–ª–µ–º—É, –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
    finally:
        await state.clear()

async def main():
    # Detect if running in Railway/production (has PORT env var) or locally
    port = os.getenv("PORT")
    railway_public_domain = os.getenv("RAILWAY_PUBLIC_DOMAIN")
    
    if port and railway_public_domain:
        # Railway/Production mode: use webhook
        from aiohttp import web
        
        # Construct webhook URL from Railway public domain
        webhook_url = f"https://{railway_public_domain}/webhook"
        print(f"Setting webhook to: {webhook_url}")
        
        try:
            await bot.set_webhook(webhook_url, drop_pending_updates=True)
            print("Webhook set successfully!")
        except Exception as e:
            print(f"Failed to set webhook: {e}")
        
        # Create aiohttp app
        app = web.Application()
        
        # Register dispatcher webhook handler
        from aiogram.webhook.aiohttp_server import SimpleRequestHandler, setup_application
        SimpleRequestHandler(dispatcher=dp, bot=bot).register(app, path="/webhook")
        
        # Add health check endpoint
        async def health(request):
            return web.Response(text="OK")
        app.router.add_get("/health", health)
        app.router.add_get("/", health)
        
        setup_application(app, dp, bot=bot)
        
        # Run web server
        port_num = int(port)
        runner = web.AppRunner(app)
        await runner.setup()
        site = web.TCPSite(runner, host="0.0.0.0", port=port_num)
        print(f"Starting webhook server on port {port_num}")
        await site.start()
        
        # Keep running
        await asyncio.Event().wait()
    else:
        # Local mode: use polling
        print("Starting in polling mode (local development)")
        await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
